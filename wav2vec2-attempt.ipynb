{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/, https://pypi.org/simple/\n",
      "Collecting reservoirpy\n",
      "  Obtaining dependency information for reservoirpy from https://test-files.pythonhosted.org/packages/e4/54/21e451f81c2523472a162e97278db2cd5db4b44e584876add12ec6629ae7/reservoirpy-0.3.10-py3-none-any.whl.metadata\n",
      "  Downloading https://test-files.pythonhosted.org/packages/e4/54/21e451f81c2523472a162e97278db2cd5db4b44e584876add12ec6629ae7/reservoirpy-0.3.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dill>=0.3.1.1 (from reservoirpy)\n",
      "  Obtaining dependency information for dill>=0.3.1.1 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from reservoirpy) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from reservoirpy) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from reservoirpy) (1.11.3)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from reservoirpy) (4.66.1)\n",
      "Downloading https://test-files.pythonhosted.org/packages/e4/54/21e451f81c2523472a162e97278db2cd5db4b44e584876add12ec6629ae7/reservoirpy-0.3.10-py3-none-any.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dill, reservoirpy\n",
      "Successfully installed dill-0.3.7 reservoirpy-0.3.10\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ reservoirpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: torchvision in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (0.16.1)\n",
      "Requirement already satisfied: torchaudio in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: transformers in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: numpy in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: requests in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load wav2vec2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "(…)2vec2-base-960h/resolve/main/config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 4.22MB/s]\n",
      "model.safetensors: 100%|██████████| 378M/378M [00:26<00:00, 14.1MB/s] \n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "(…)-960h/resolve/main/tokenizer_config.json: 100%|██████████| 163/163 [00:00<00:00, 417kB/s]\n",
      "(…)v2vec2-base-960h/resolve/main/vocab.json: 100%|██████████| 291/291 [00:00<00:00, 1.30MB/s]\n",
      "(…)60h/resolve/main/special_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 201kB/s]\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "/Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:733: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Model, Wav2Vec2Tokenizer\n",
    "import librosa\n",
    "import torch\n",
    "\n",
    "# Charger le modèle pré-entraîné et le tokenizer\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute all segments of 5 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "def split_audio_files(filenames, ratings, folder_path, output_folder, target_length=5.0):\n",
    "    \"\"\"\n",
    "    Découpe tous les fichiers audio dans le dossier spécifié en segments de 5 secondes.\n",
    "    Les segments inférieurs à 5 secondes sont ignorés.\n",
    "\n",
    "    :param folder_path: Chemin vers le dossier contenant les fichiers audio.\n",
    "    :param target_length: Longueur cible pour les segments, en secondes.\n",
    "    \"\"\"\n",
    "    for i, file_name in enumerate(filenames):\n",
    "        if file_name.endswith('.wav'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # Calculer le nombre de samples pour 5 secondes\n",
    "            target_samples = int(target_length * sr)\n",
    "\n",
    "            # Découper en segments de 5 secondes\n",
    "            for start in range(0, len(audio), target_samples):\n",
    "                end = start + target_samples\n",
    "\n",
    "                # Ignorer les segments de moins de 5 secondes\n",
    "                if end <= len(audio):\n",
    "                    segment = audio[start:end]\n",
    "                    segment_file_name = f\"{file_name[:-4]}_segment_{start // target_samples}_r{ratings[i]}.wav\"\n",
    "                    segment_file_path = os.path.join(output_folder, segment_file_name)\n",
    "\n",
    "                    # Enregistrer le segment\n",
    "                    sf.write(segment_file_path, segment, sr)\n",
    "\n",
    "# Read the csv file containing the filenames and ratings\n",
    "df_source = pd.read_csv('./data-csv/tchatche_split_x.csv')\n",
    "\n",
    "# Utiliser la fonction\n",
    "split_audio_files(df_source['file_name'], df_source['rating'], 'raw-audio', 'raw-audio-segments')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and extract features from wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1624/1624 [03:38<00:00,  7.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QG_20230530144858_1_2818740_3060040_9657_12008...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[tensor(-0.0926), tensor(-0.0106), tensor(-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QG_20230530144858_1_2818740_3060040_9657_12008...</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[tensor(-0.0926), tensor(-0.0106), tensor(-0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  rating  \\\n",
       "0  QG_20230530144858_1_2818740_3060040_9657_12008...       5   \n",
       "1  QG_20230530144858_1_2818740_3060040_9657_12008...       5   \n",
       "\n",
       "                                            features  \n",
       "0  [[[tensor(-0.0926), tensor(-0.0106), tensor(-0...  \n",
       "1  [[[tensor(-0.0926), tensor(-0.0106), tensor(-0...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the directory path\n",
    "dir_path = './raw-audio-segments'\n",
    "\n",
    "# Retrieve all filenames in the directory\n",
    "filenames = os.listdir(dir_path)\n",
    "\n",
    "# all_features\n",
    "data = []\n",
    "\n",
    "# Loop through the list of .wav files and compute features from MFCC for each file\n",
    "for filename in tqdm(filenames):\n",
    "\n",
    "    # Get rating from filename\n",
    "    rating = int(filename.split('_')[-1][1])\n",
    "\n",
    "    # Charger et préparer l'audio (exemple)\n",
    "    audio_input, sampling_rate = librosa.load(os.path.join(dir_path, filename), sr=16000)\n",
    "\n",
    "    # Tokenize et extraire les features\n",
    "    input_values = tokenizer(audio_input, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        features = model(input_values).last_hidden_state\n",
    "    \n",
    "    data.append({\n",
    "        'file_name': filename,\n",
    "        'rating': rating,\n",
    "        'features': features\n",
    "    })\n",
    "    \n",
    "    # Append features to list\n",
    "    line = {'file_name': filename, 'rating': rating, 'features': features}\n",
    "    data.append(line)\n",
    "\n",
    "# Create a dataframe from the list of features\n",
    "df = pd.DataFrame(data)\n",
    "df.head(2)\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "df.to_csv('./data-csv/tchatche_split_wav2vec2_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt with reservoirpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3248, 249, 768) (3248, 249)\n",
      "(2598, 249, 768) (650, 249, 768) (2598, 249) (650, 249)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "ratings = []\n",
    "for i, row in df.iterrows():\n",
    "    ratings += [row['rating'] for _ in range(row['features'].shape[1])]\n",
    "    data += [row['features'].squeeze().numpy()]\n",
    "\n",
    "data = np.array(data)\n",
    "ratings = np.array(ratings).reshape(-1, data.shape[1])\n",
    "print(data.shape, ratings.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, ratings, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.nodes import Reservoir, Ridge, Input, ESN\n",
    "\n",
    "#data = Input(input_dim=1)\n",
    "reservoir = Reservoir(4000, lr=0.2, sr=1.1)\n",
    "readout = Ridge(ridge=1e-8)\n",
    "esn = ESN(reservoir=reservoir, readout=readout, workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ESN-1:  22%|██▏       | 580/2598 [00:44<02:35, 13.00it/s]/Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Running ESN-1: 100%|██████████| 2598/2598 [03:22<00:00, 12.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting node ESN-1...\n"
     ]
    }
   ],
   "source": [
    "forecast = esn.fit(X_train, y_train.reshape(-1, 249, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ESN-1: 100%|██████████| 650/650 [00:37<00:00, 17.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.104050652209672"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = esn.run(X_test)\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "mean_squared_error(y_pred.mean(axis=1), y_test.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche d'hyper-paramètres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(dataset, config, *, iss, N, sr, lr, ridge):\n",
    "    dataset = ((X_train, y_train), (X_test, y_test))\n",
    "\n",
    "    reservoir = Reservoir(N, lr=lr, sr=sr, input_scaling=iss)\n",
    "    readout = Ridge(ridge=ridge)\n",
    "    esn = ESN(reservoir=reservoir, readout=readout, workers=-1)\n",
    "\n",
    "    esn.fit(X_train, y_train.reshape(-1, 249, 1))\n",
    "\n",
    "    y_pred = np.array(esn.run(X_test))\n",
    "    y_pred = y_pred.reshape(y_pred.shape[0], y_pred.shape[1])\n",
    "    return {\"loss\":mean_squared_error(y_pred.mean(axis=1), y_test.mean(axis=1))}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_config = {\n",
    "    \"exp\": \"hyperopt-bert-1\", # the experimentation name\n",
    "    \"hp_max_evals\": 200,             # the number of differents sets of parameters hyperopt has to try\n",
    "    \"hp_method\": \"random\",           # the method used by hyperopt to chose those sets (see below)\n",
    "    \"seed\": 42,                      # the random state seed, to ensure reproducibility\n",
    "    \"instances_per_trial\": 1,        # how many random ESN will be tried with each sets of parameters\n",
    "    \"hp_space\": {                    # what are the ranges of parameters explored\n",
    "        \"N\": [\"choice\", 1500],             # the number of neurons is fixed to 500\n",
    "        \"sr\": [\"loguniform\", 1e-3, 100],   # the spectral radius is log-uniformly distributed between 1e-2 and 10\n",
    "        \"lr\": [\"loguniform\", 1e-3, 1],  # idem with the leaking rate, from 1e-3 to 1\n",
    "        \"iss\": [\"loguniform\", 1e-2, 1e1],           # the input scaling is fixed\n",
    "        \"ridge\": [\"loguniform\", 1e-8, 1e-3],        # and so is the regularization parameter.\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "# we precautionously save the configuration in a JSON file\n",
    "# each file will begin with a number corresponding to the current experimentation run number.\n",
    "with open(f\"{hyperopt_config['exp']}.config.json\", \"w+\") as f:\n",
    "    json.dump(hyperopt_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from hyperopt) (1.26.2)\n",
      "Requirement already satisfied: scipy in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from hyperopt) (1.11.3)\n",
      "Requirement already satisfied: six in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from hyperopt) (3.2.1)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/naowak/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages (from hyperopt) (4.66.1)\n",
      "Collecting cloudpickle (from hyperopt)\n",
      "  Obtaining dependency information for cloudpickle from https://files.pythonhosted.org/packages/96/43/dae06432d0c4b1dc9e9149ad37b4ca8384cf6eb7700cd9215b177b914f0a/cloudpickle-3.0.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting py4j (from hyperopt)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492024 sha256=d8b01685f982779876b8f4a1b334232a5f733e1ec65629ca7f9651ab85bfb5dc\n",
      "  Stored in directory: /Users/naowak/Library/Caches/pip/wheels/da/19/ca/9d8c44cd311a955509d7e13da3f0bea42400c469ef825b580b\n",
      "Successfully built future\n",
      "Installing collected packages: py4j, future, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-3.0.0 future-0.18.3 hyperopt-0.2.7 py4j-0.10.9.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 91/200 [1:30:38<1:48:34, 59.76s/trial, best loss: 2.6167795378239616]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb Cellule 19\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m verbosity(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m (X_train[:\u001b[39m500\u001b[39m, :, :], y_train[:\u001b[39m500\u001b[39m, :]), (X_test[:\u001b[39m150\u001b[39m, :, :], y_test[:\u001b[39m150\u001b[39m, :])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m best \u001b[39m=\u001b[39m research(objective, dataset, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mhyperopt_config[\u001b[39m'\u001b[39;49m\u001b[39mexp\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m.config.json\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/hyper/_hypersearch.py:187\u001b[0m, in \u001b[0;36mresearch\u001b[0;34m(objective, dataset, config_path, report_path)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     rs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mdefault_rng(config[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 187\u001b[0m best \u001b[39m=\u001b[39m hopt\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    188\u001b[0m     objective_wrapper,\n\u001b[1;32m    189\u001b[0m     space\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m    190\u001b[0m     algo\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mhp_method\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    191\u001b[0m     max_evals\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mhp_max_evals\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    192\u001b[0m     trials\u001b[39m=\u001b[39;49mtrials,\n\u001b[1;32m    193\u001b[0m     rstate\u001b[39m=\u001b[39;49mrs,\n\u001b[1;32m    194\u001b[0m )\n\u001b[1;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m best, trials\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/hyper/_hypersearch.py:139\u001b[0m, in \u001b[0;36mresearch.<locals>.objective_wrapper\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 139\u001b[0m     returned_dict \u001b[39m=\u001b[39m objective(dataset, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    142\u001b[0m     duration \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m start\n",
      "\u001b[1;32m/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb Cellule 19\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m readout \u001b[39m=\u001b[39m Ridge(ridge\u001b[39m=\u001b[39mridge)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m esn \u001b[39m=\u001b[39m ESN(reservoir\u001b[39m=\u001b[39mreservoir, readout\u001b[39m=\u001b[39mreadout, workers\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m esn\u001b[39m.\u001b[39;49mfit(X_train, y_train\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m249\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(esn\u001b[39m.\u001b[39mrun(X_test))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/naowak/Thesis/code/tchatche/ai-hackatech/wav2vec2-attempt.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mreshape(y_pred\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/nodes/esn.py:335\u001b[0m, in \u001b[0;36mESN.fit\u001b[0;34m(self, X, Y, warmup, from_state, stateful, reset)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, Y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, warmup\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, from_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stateful\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    334\u001b[0m     X, Y \u001b[39m=\u001b[39m to_data_mapping(\u001b[39mself\u001b[39m, X, Y)\n\u001b[0;32m--> 335\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_on_sequence(X[\u001b[39m0\u001b[39;49m], Y[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    337\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialize_buffers()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\n\u001b[1;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msequential\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthreading\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    342\u001b[0m     ):\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/model.py:391\u001b[0m, in \u001b[0;36mModel._initialize_on_sequence\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m         y_init \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_2d(Y[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 391\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitialize(x_init, y_init)\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/model.py:777\u001b[0m, in \u001b[0;36mModel.initialize\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call the Model initializers on some data points.\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[39mModel will be virtually run to infer shapes of all nodes given\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[39minputs and targets vectors.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39m    Initialized Model.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_initialized \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 777\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initializer(\u001b[39mself\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my)\n\u001b[1;32m    778\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    779\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/model.py:265\u001b[0m, in \u001b[0;36minitializer\u001b[0;34m(model, x, y)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m# first, probe network to init forward flow\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m# (no real call, only zero states)\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnodes:\n\u001b[0;32m--> 265\u001b[0m     node\u001b[39m.\u001b[39;49minitialize(x\u001b[39m=\u001b[39;49mdata[node]\u001b[39m.\u001b[39;49mx, y\u001b[39m=\u001b[39;49mdata[node]\u001b[39m.\u001b[39;49my)\n\u001b[1;32m    267\u001b[0m \u001b[39m# second, probe feedback demanding nodes to\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[39m# init feedback flow\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[39mfor\u001b[39;00m fb_node \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mfeedback_nodes:\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/node.py:678\u001b[0m, in \u001b[0;36mNode.initialize\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_initialized:\n\u001b[1;32m    677\u001b[0m     x_init, y_init \u001b[39m=\u001b[39m _init_vectors_placeholders(\u001b[39mself\u001b[39m, x, y)\n\u001b[0;32m--> 678\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initializer(\u001b[39mself\u001b[39;49m, x\u001b[39m=\u001b[39;49mx_init, y\u001b[39m=\u001b[39;49my_init)\n\u001b[1;32m    679\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_initialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/nodes/reservoirs/base.py:138\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(reservoir, x, sr, input_scaling, bias_scaling, input_connectivity, rc_connectivity, W_init, Win_init, bias_init, input_bias, seed, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         reservoir\u001b[39m.\u001b[39mhypers[\u001b[39m\"\u001b[39m\u001b[39munits\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m W\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    137\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcallable\u001b[39m(W_init):\n\u001b[0;32m--> 138\u001b[0m     W \u001b[39m=\u001b[39m W_init(\n\u001b[1;32m    139\u001b[0m         reservoir\u001b[39m.\u001b[39;49moutput_dim,\n\u001b[1;32m    140\u001b[0m         reservoir\u001b[39m.\u001b[39;49moutput_dim,\n\u001b[1;32m    141\u001b[0m         sr\u001b[39m=\u001b[39;49msr,\n\u001b[1;32m    142\u001b[0m         proba\u001b[39m=\u001b[39;49mrc_connectivity,\n\u001b[1;32m    143\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    144\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(dtype_msg\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(\u001b[39mtype\u001b[39m(W_init)), reservoir\u001b[39m.\u001b[39mname, \u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/mat_gen.py:237\u001b[0m, in \u001b[0;36mInitializer.__call__\u001b[0;34m(self, *shape, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m init\u001b[39m.\u001b[39m_autorize_rescaling:\n\u001b[0;32m--> 237\u001b[0m         \u001b[39mreturn\u001b[39;00m init\u001b[39m.\u001b[39;49m_func_post_process(\u001b[39m*\u001b[39;49mshape, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit\u001b[39m.\u001b[39;49m_kwargs)\n\u001b[1;32m    238\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m         \u001b[39mreturn\u001b[39;00m init\u001b[39m.\u001b[39m_func(\u001b[39m*\u001b[39mshape, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit\u001b[39m.\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/mat_gen.py:255\u001b[0m, in \u001b[0;36mInitializer._func_post_process\u001b[0;34m(self, sr, input_scaling, *shape, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39msr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39minput_scaling\u001b[39m\u001b[39m'\u001b[39m\u001b[39m parameters are mutually exclusive for a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgiven matrix.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m sr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     \u001b[39mreturn\u001b[39;00m _scale_spectral_radius(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, shape, sr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    256\u001b[0m \u001b[39melif\u001b[39;00m input_scaling \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m _scale_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, shape, input_scaling, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/mat_gen.py:349\u001b[0m, in \u001b[0;36m_scale_spectral_radius\u001b[0;34m(w_init, shape, sr, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m convergence:\n\u001b[1;32m    346\u001b[0m     \u001b[39m# make sure the eigenvalues are reachable.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[39m# (maybe find a better way to do this on day)\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m         current_sr \u001b[39m=\u001b[39m spectral_radius(w)\n\u001b[1;32m    350\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m_epsilon \u001b[39m<\u001b[39m current_sr \u001b[39m<\u001b[39m _epsilon:\n\u001b[1;32m    351\u001b[0m             current_sr \u001b[39m=\u001b[39m _epsilon  \u001b[39m# avoid div by zero exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/reservoirpy/observables.py:89\u001b[0m, in \u001b[0;36mspectral_radius\u001b[0;34m(W, maxiter)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mif\u001b[39;00m maxiter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m         maxiter \u001b[39m=\u001b[39m W\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m20\u001b[39m\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(\n\u001b[0;32m---> 89\u001b[0m         \u001b[39mabs\u001b[39m(eigs(W, k\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, which\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mLM\u001b[39;49m\u001b[39m\"\u001b[39;49m, maxiter\u001b[39m=\u001b[39;49mmaxiter, return_eigenvectors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, v0\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mones(W\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], W\u001b[39m.\u001b[39;49mdtype)))\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m(\u001b[39mabs\u001b[39m(linalg\u001b[39m.\u001b[39meig(W)[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1352\u001b[0m, in \u001b[0;36meigs\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001b[0m\n\u001b[1;32m   1350\u001b[0m \u001b[39mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[1;32m   1351\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m params\u001b[39m.\u001b[39mconverged:\n\u001b[0;32m-> 1352\u001b[0m         params\u001b[39m.\u001b[39;49miterate()\n\u001b[1;32m   1354\u001b[0m     \u001b[39mreturn\u001b[39;00m params\u001b[39m.\u001b[39mextract(return_eigenvectors)\n",
      "File \u001b[0;32m~/Thesis/code/tchatche/venv_tchatche/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:724\u001b[0m, in \u001b[0;36m_UnsymmetricArpackParams.iterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39miterate\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtp \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfd\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    723\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mido, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miparam, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mipntr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo \u001b[39m=\u001b[39m\\\n\u001b[0;32m--> 724\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arpack_solver(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mido, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbmat, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwhich, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk,\n\u001b[1;32m    725\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miparam,\n\u001b[1;32m    726\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mipntr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkd, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mworkl,\n\u001b[1;32m    727\u001b[0m                                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minfo)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    729\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mido, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miparam, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mipntr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo \u001b[39m=\u001b[39m\\\n\u001b[1;32m    730\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_arpack_solver(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mido, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbmat, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhich, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk,\n\u001b[1;32m    731\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtol, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miparam,\n\u001b[1;32m    732\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mipntr, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkd, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkl,\n\u001b[1;32m    733\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrwork, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from reservoirpy.hyper import research\n",
    "from reservoirpy import verbosity\n",
    "verbosity(0)\n",
    "dataset = (X_train[:500, :, :], y_train[:500, :]), (X_test[:150, :, :], y_test[:150, :])\n",
    "\n",
    "best = research(objective, dataset, f\"{hyperopt_config['exp']}.config.json\", \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tchatche",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
